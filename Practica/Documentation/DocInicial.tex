\PassOptionsToPackage{table}{xcolor}
\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{scrextend} % lists
\usepackage{float}
\addtokomafont{labelinglabel}{\bfseries}

\title{Music recomendation}
\author{Raquel Leandra Pérez Arnal y Adrián Sánchez Albanell}
\date{} % Sin fecha.

\definecolor{light-gray}{gray}{0.95}

\begin{document}
\begin{titlepage}
	\centering
	{\scshape\LARGE Grado en Ingenieria Informatica - UPC \par}
	\vspace{1cm}
	{\scshape\Large Proyecto Aprendizaje Autónomo (APA)\par}
	\vspace{1.5cm}
	{\huge\bfseries KKBox's Music Recommendation Challenge\par}
	\vspace{2cm}
	{\Large\itshape Raquel Leandra Pérez Arnal y Adrián Sánchez Albanell\par}
\end{titlepage}
\clearpage
{\hypersetup{linkcolor=black}
\tableofcontents
}
\cleardoublepage

\section{Descripción del trabajo}


\subsection{Introducción}

Este trabajo consiste en elegir un problema de regresión o clasificación y generar un modelo para resolverlo. Para ello usaremos algunos de los métodos, lineales y no lineales, vistos en clase durante el curso de Aprendizaje Autónomo.\\

Hemos elegido un problema de \href{https://www.kaggle.com/competitions}{kaggle competitions} sobre recomendación de música llamado \href{https://www.kaggle.com/c/kkbox-music-recommendation-challenge}{WSDM - KKBox's Music Recommendation Challenge}. Este consiste en un conjunto de datos, proporcionado por \href{https://www.kkbox.com/intl/index.php?area=intl}{KKBOX} - servició de streaming de música asiático - con información sobre diferentes canciones, usuarios y como ha sido el acceso de los usuarios a dichas canciones.\\

Nuestro objetivo es predecir si un usuario que ha escuchado una canción lo volverá a hacer en un periodo de tiempo determinado, por lo tanto se trata de un problema de clasificación binaria: si el usuario volverá a escuchar o no una canción que ya ha oído anteriormente.


\subsection{Conjunto de datos disponible}

Kaggle nos ha proporcionado los datos en seis ficheros con formato CSV, de los cuales usaremos cuatro para la práctica. Los dos restantes són un conjunto de datos de muestra sobre como enviar los datos para el concurso y los datos de test para el concurso (que no nos sirven ya que no tienen la variable target).

\subsection*{train.csv}

Contiene la información de las reproducciones de canciones por parte del usuario. Tiene las siguientes variables:

\begin{labeling}{source\_screen\_name}
\item [msno] identificador del usuario.
\item [song\_id] identificador de la canción.
\item [source\_system\_tab] nombre de la pestaña donde se selecciono el evento.\\
Ejemplos: \textit{my library}, \textit{search}, etc.
\item [source\_screen\_name] nombre de la pantalla que ve el usuario.
\item [source\_type] des de donde se ha reproducido la canción.\\
Ejemplos: \textit{album}, \textit{online-playlist}, \textit{song}, etc.
\item [target] variable de target. Si el usuario ha escuchado la canción más de una vez en un intervalo de un mes target es 1, si no es 0.
\end{labeling}

\subsection*{members.csv}

Contiene información de los usuarios. Tiene las siguientes variables:

\begin{labeling}{registration\_init\_time}
\item [msno] identificador del usuario.
\item [city] identificador de ciudad.
\item [bd] edad del usuario. Contiene valores outlier.
\item [gender] genero del usuario. Puede ser \textit{female} o \textit{male}.
\item [registered\_via] identificador del método de registro de usuario.
\item [registration\_init\_time] día del registro de usuario, en formato \textit{\%Y\%m\%d}.
\item [expiration\_date] día de expiración del registro de usuario, en formato \textit{\%Y\%m\%d}.
\end{labeling}

\subsection*{songs.csv}

Contiene información de las canciones. Tiene las siguientes variables:

\begin{labeling}{song\_length}
\item [song\_id] identificador de la canción.
\item [song\_length] duración de la canción en milisegundos.
\item [genre\_ids] género musical de la canción. Hay canciones con más de un genero, donde el carácter | hace de separador.
\item [artist\_name] nombre del artista.
\item [composer] nombre del compositor o compositores. Si hay más de uno el carácter | hace de separador.
\item [lyricist] nombre del escritor o escritores de la canción. Si hay más de uno el carácter | hace de separador.
\item [language] identificador del lenguaje de la canción.
\end{labeling}

\subsection*{song\_extra\_info.csv}

Contiene información extra de las canciones. Tiene las siguientes variables:

\begin{labeling}{song\_name}
\item [song\_id] identificador de la canción.
\item [song\_name] nombre de la canción.
\item [isrc] \href{https://en.wikipedia.org/wiki/International_Standard_Recording_Code}{International Standard Recording Code}. En teoría se puede usar como identificador de la canción, pero hay codigos ISRC sin verificar. Contiene información de la canción aunque puede ser erronea o confusa como el country code, que no se refiere a la canción si no a la agencia que proporciona el codigo ISRC.
\end{labeling}

\subsection{Notas sobre el lenguaje de programación escogido, Python}

El lenguaje de programación usado para realizar esta práctica tenía que ser R. Sin embargo pronto nos dimos cuenta de que, debido al tamaño de los datos de muestra, nuestro desconocimiento de como usarlo para trabajar con grandes cantidades de datos eficientemente y el material de que disponemos, nos iba a ser imposible trabajar con este lenguaje.\\

Debido a esto, hemos decidido usar Python, lenguaje muy usado en Machine Learning y con muchos recursos para trabajar comodamente en este ambito. Python es bastante más eficiente que R gestionando memória y más rápido en cuanto a tiempo de ejecución.\\

Usar Python no ha solucionado todos los problemas generados por tener tantos datos, pero nos ha permitido trabajar mejor y realizar muchas cosas que con R nos habrian sido o imposibles o muy dificiles.


\section{Trabajo Relacionado}

%\section{Posibles Métodos}
%\begin{itemize}
%\item logistic regression, multinomial regression
%(single-layer MLP), LDA, QDA, RDA, \textbf{Naive Bayes}, \textbf{nearest-neighbours},\textbf{linear SVM}, quadratic SVM
%\item one-hidden-layer MLP, the RBFNN, the SVM with RBF kernel, a
%Random Forest
%\end{itemize}


\section{Análisis y preprocesamiento de los datos}

\subsection{Análisis inicial de los datos}

Partiendo de los datos iniciales (descritos en el apartado \textit{Conjunto de datos disponible}) hemos generado un solo data frame uniendo primero la información de \textbf{members} y \textbf{train} por \textit{msno}, y luego uniendo el resultado a \textbf{songs} y \textbf{song\_extra\_info} por \textit{song\_id}. Al nuevo conjunto de datos con toda la información lo llamaremos \textbf{merged}. El nuevo conjunto de datos se compone de $20$ variables y $7377418$ muestras diferentes. La siguiente tabla nos muestra información sobre los valores perdidos en cada variable y su tipo:
\begin{table}[H]
\centering
\rowcolors{1}{white}{light-gray}
\begin{tabular}{l*{4}l}
\hiderowcolors
\textbf{Variable}          & \textbf{Valores perdidos} & \textbf{Porcentage}  & \textbf{Tipo de datos} \\
\showrowcolors
\hline 
\textbf{msno}                     & 0                 & 0           & categóricos (object)                    \\
\textbf{song\_id}                 & 0                 & 0           & categóricos (object)                    \\
\textbf{source\_system\_tab}      & 24849             & 0.3368      & categóricos (object)                    \\
\textbf{source\_screen\_name}     & 414804            & 5.6226      & categóricos (object)                    \\
\textbf{source\_type}             & 21539             & 0.2919      & categóricos (object)                    \\
\textbf{target}                   & 0                 & 0           & categóricos (uint8)                     \\
\textbf{city}                     & 0                 & 0           & categóricos (int64)                     \\
\textbf{bd}                       & 0                 & 0           & numéricos (int64)                       \\
\textbf{gender}                   & 2961479           & 40.142      & categóricos (object)                    \\
\textbf{registered\_via}          & 0                 & 0           & categóricos (int64)                     \\
\textbf{registration\_init\_time} & 0                 & 0           & numéricos (int64) (\textit{\%Y\%m\%d})  \\
\textbf{expiration\_date}         & 0                 & 0           & numéricos (int64)  (\textit{\%Y\%m\%d}) \\
\textbf{song\_length}             & 114               & 0.0015      & numéricos (float64)                     \\
\textbf{genre\_ids}               & 118455            & 1.605       & categóricos (object)                    \\
\textbf{artist\_name}             & 114               & 0.0015      & categóricos (object)                    \\
\textbf{composer}                 & 1675706           & 22.7139     & categóricos (object)                    \\
\textbf{lyricist}                 & 3178798           & 43.0882     & categóricos (object)                    \\
\textbf{language}                 & 150               & 0.0020      & categóricos (float64)                   \\
\textbf{name}                     & 1457              & 0.0197      & categóricos (object)                    \\
\textbf{isrc}                     & 577858            & 7.8327      & categóricos (object)                    \\
\end{tabular}
\caption{\textit{Información general sobre el conjunto de datos merged.}}
\end{table}
En la tabla siguiente vemos de cuantas categorías consta cada variable categórica. Esto es muy importante en nuestro caso porque contamos con un conjunto de datos muy grande y el número de categorías añade mucha complejidad a los datos cuando queramos diseñar los diferentes modelos:
\begin{table}[H]
\centering
\rowcolors{1}{white}{light-gray}
\begin{tabular}{l*{2}l}
\hiderowcolors
\textbf{Variable}                   & \textbf{Número de categorías} \\
\showrowcolors
\hline 
\textbf{msno}                     & 30755   \\
\textbf{song\_id}                 & 359966  \\
\textbf{source\_system\_tab}      & 8       \\
\textbf{source\_screen\_name}     & 20      \\
\textbf{source\_type}             & 12      \\
\textbf{target}                   & 2       \\
\textbf{city}                     & 21      \\
\textbf{gender}                   & 2       \\
\textbf{registered\_via}          & 5       \\
\textbf{genre\_ids}               & 166     \\
\textbf{artist\_name}             & 40582   \\
\textbf{composer}                 & 81566   \\
\textbf{lyricist}                 & 38473   \\
\textbf{language}                 & 10      \\
\textbf{name}                     & 234144  \\
\textbf{isrc}                     & 269760  \\
\end{tabular}
\caption{\textit{Número de categorías en las variables categóricas del conjunto de datos.}}
\end{table}
Con esta información pasaremos a tratar los datos para preprocesarlos.

\subsection{Tratamiento de valores perdidos}

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{Images/lost_values_percent.png}
\caption{\textit{En esta gráfica podemos ver porcentage de valores perdidos en cada variable del conjunto final de datos.}}
\end{figure}

Como podemos ver en \textit{Table 1} y \textit{Figure 1} tenemos varias variables donde hay valores perdidos y que trataremos de diferentes maneras.\\

\begin{itemize}
\item Las variables \textit{lyricist} y \textit{gender} hemos decidido eliminarlas por tener un porcentage muy alto de valores perdidos, más de un $40\%$. 
\item La variable \textit{composer} también hemos decidido eliminarla. Aunque el porcentage de valores perdidos en esta variable es un $22.71\%$, un valor alto pero que podriamos haber decidido imputar por ejemplo, cuenta con $81566$ categorías diferentes. Teniendo en cuenta el tamaño de nuestro conjunto de datos, la complejidad que añade esta variable nos es intratable con el conocimiento y material del que disponemos.
\item El resto de variables tienen menos de un $10\%$ de valores perdidos. Podriamos haberlos imputado a partir del resto de datos, pero disponemos de un conjunto de datos lo bastante grande como para poder eliminar las muestras donde aparecen valores nulos sin problemas.
\end{itemize}
Después de tratar los valores perdidos en el conjunto de datos este consta de 17 variables y 6317407 muestras.

\subsection{Tratamiento de outliers}

La única variable que contiene outliers es \textit{bd}, que representa la edad de un usuario, y tiene valores imposibles (como 0 años). Lo primero que hemos hecho ha sido eliminarlos, convirtiendo los valores menores a 16 y los mayores a 90 en valores nulos.\\

Habiamos pensado en imputar el valor de los outliers mediante KNN, pero al convertirlos en valores nulos hemos visto que un $39.68\%$ de \textit{bd} són outliers. Al ver esto hemos decidido que lo mejor era simplemente eliminar esta variable.

\subsection{Creación de nuevas variables}

La variable \textit{ISRC} representa el \href{https://en.wikipedia.org/wiki/International_Standard_Recording_Code}{International Standard Recording Code} de la canción. Este codigo tiene un formato de 12 carácteres y cuatro partes de la forma CC-XXX-YY-NNNNN, donde:

\begin{labeling}{source\_screen\_name}
\item [CC] identificador del país del emisor del código ISRC.
\item [XXX] codigo numérico identificador del emisor del código ISRC.
\item [YY] dos últimos digitos del año en que el código ISRC fue asignado a la grabación.
\item [NNNNN] identificador numérico de la grabación.
\end{labeling}

De esta variable crearemos una nueva variable con el año en que se registro el codigo de la grabación, ya que nos ha parecido un valor representativo para el conjunto, a la que llamaremos \textit{song\_year}. Para hacerlo cogeremos los dos dígitos YY del código ISRC, los valores mayores a 18 los convertimos en valores numéricos de la forma 19YY, el resto de la forma 20YY.

\subsection{Selección de features}
Hay dos grandes motivos por los que hemos eliminado features: 

\begin{itemize}
\item La feature en cuestión es un \textbf{identificador}, es decir, es una variable cuyo único objetivo es identificar la muestra o alguna de sus partes. Los hemos utilizado para unir los distintos conjuntos de datos, pero de cara al análisis no tienen utilidad.
\item Algunas de las variables eran \textbf{computacionalmente intratatable}, esto se debe a que tienen tal cantidad de categorías, que al intentar procesarlas con los conocimientos y hardware que tenemos se vuelven intratables (tanto en python como en R).
\end{itemize}

\begin{table}[H]
\centering
\caption{My caption}
\label{my-label}
\begin{tabular}{|l|l|}
\hline
Nombre                   & Motivo \\ \hline
msno                     & Es solo un identificador \\ \hline
song\_id                 & Es solo un identificadors \\ \hline
artist\_name             & Computacionalmente intratable \\ \hline
composer                 & Computacionalmente intratable \\ \hline
lyricist                 & Computacionalmente intratable    \\ \hline
name                     & Computacionalmente intratable     \\ \hline
isrc                     & Es solo un identificador    \\ \hline
\end{tabular}
\end{table}

\subsection{Codificación de variables categóricas}

\subsection{Estandarización}

\subsection{Transformación de variables}

\section{Protocolo de re-muestreo}
Una vez preprocesados los datos, a la hora de entrenar los métodos hemos separado en dos conjuntos conjuntos de datos, 
con objetivo de poder comparar bien los resultados. Obteniendo de esta forma: 

\begin{table}[H]
\centering
\caption{Partición de los datos}
\label{my-label}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Subconjunto}              & \textbf{Proporción}   & \textbf{Tamaño}    \\ \hline
Entrenamiento                     & 0.7                   & 4,422,186   \\ \hline
Test                              & 0.3                   & 1,895,223   \\ \hline
Total                             & 1                     & 6,317,409   \\ \hline
\end{tabular}
\end{table}

Hemos tomado un 30\% de los datos para test con el objetivo de, por un lado obtener unos resultados más estables a la hora de 
comparar los distintos modelos, además de esta forma reducimos la cantidad de datos de entrenamiento a una cantidad ligeramente 
más tratable a nivel computacional. Puesto a que con tal cantidad de datos la potencia computacional y el tiempo de procesamiento es 
bastante considerable. 

Además para algunos modelos hemos tenido que calcular hiper-parámetros. Para ello hemos utilizado \textit{Random Search Cross-Validation}.

Con tal cantidad de datos nos podríamos haber limitado a tomar una partición de validación para buscar los mejores hiper-parámetros, pero de 
esta forma teníamos que entrenar iterativamente cada modelo con los diferentes hiper-parámetros a comprobar, para luego analizar los resultados obtenidos con la partición de validación. El problema en este caso es que cuando había que buscar varios hiper-parámetros para un mismo modelo no sabíamos paralelizar el proceso, haciendo que de esta forma fuera significativamente más lento que otras opciones ya implementadas en la librería utilizada, como serían \textit{sklearn.model\_selection.GridSearchCV} \textit{sklearn.model\_selection.RandomizedSearchCV}. Entre estas dos opciones decidimos utilizar \textit{RandomizedSearchCV}, por ser más rápida sin tener unos peores resultados por ello. 

\textbf{sklearn.model\_selection.RandomizedSearchCV} es un método de \textit{sklearn} que aplica \textit{3-fold stratified cross-validation} a una muestra aleatoria de los hiper-parámetros que queremos obtener. A diferencia con \textit{Grid-Search CV}, este método no prueba todas las posibles opciones, lo que implica una menor cantidad de entrenamientos del modelo, y por tanto un coste muy inferior respecto al tiempo  total, sin perder demasiada accuracy por el camino. Como se puede ver en \cite{randomSearch} es especialmente efectivo con conjuntos de validación grandes, como es nuestro caso. 

\section{Resultados de los métodos lineales}
logistic regression, multinomial regression
(single-layer MLP), LDA, QDA, RDA, \textbf{Naive Bayes}, \textbf{nearest-neighbours},\textbf{linear SVM}, quadratic SVM
\section{Resultados de los métodos no lineales}
one-hidden-layer MLP, the RBFNN, the SVM with RBF kernel, a
Random Forest
\section{Descripción y justificación del modelo escogido}

\section{Conclusiones}

\bibliographystyle{unsrt}
\bibliography{biblio}


\end{document}
